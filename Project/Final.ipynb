{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from skimage import measure\n",
    "from tensorflow import keras\n",
    "from PIL import Image \n",
    "import imageio\n",
    "import skimage.io\n",
    "import math\n",
    "\n",
    "\n",
    "from scipy.ndimage.morphology import binary_closing, binary_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    video_frames = []\n",
    "    ret, frame = cap.read()\n",
    "    while ret :\n",
    "        video_frames.append(frame)\n",
    "        ret, frame = cap.read()\n",
    "    return np.array(video_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_arrow(img):\n",
    "    w,h,c = img.shape\n",
    "    arrow = np.zeros([w,h])\n",
    "    stds = np.std(img,axis = 2)\n",
    "    arrow[(np.argmax(img,axis=2) == 2) * (stds > 10)] = 255\n",
    "    return arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_path(video_frame):\n",
    "    path = []\n",
    "    for img in video_frames:\n",
    "        arrow = detect_arrow(img)\n",
    "        cy,cx = ndimage.measurements.center_of_mass(arrow)\n",
    "        path.append((int(cx),int(cy)))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_pass_filter(img,size):\n",
    "    '''\n",
    "    Low-pass filter applied to the simple images in order to get rid of noise.\n",
    "    \n",
    "    Input: grayscale image\n",
    "    Output: filtered image\n",
    "    \n",
    "    '''\n",
    "    Kernel = np.ones((size,size),np.float32)/size**2\n",
    "    return ndimage.filters.convolve(img, Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binaryImage(im):\n",
    "    '''\n",
    "    Threshold function that returns values of 0 or 255 if image pixel values are within thresholds\n",
    "    \n",
    "    Input: image\n",
    "    Output: 0 or 255 'binary' image\n",
    "    '''\n",
    "    im_filt = cv2.medianBlur(im,1)\n",
    "    im_binary = cv2.inRange(im_filt,100,255) #threshold values found from \n",
    "    return im_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_rectangle(im, param):\n",
    "    [h,w] = im.shape\n",
    "    region = []\n",
    "    corner = [] \n",
    "    \n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            if im[i,j] == 255:\n",
    "                region.append([i,j])\n",
    "    region = np.array(region)\n",
    "    \n",
    "    max_x = np.max(region[:,1])\n",
    "    min_x = np.min(region[:,1])\n",
    "    max_y = np.max(region[:,0])\n",
    "    min_y = np.min(region[:,0])  \n",
    "    \n",
    "    left = min_x-param\n",
    "    top = min_y-param\n",
    "    right = max_x+param\n",
    "    bottom = max_y+param\n",
    "    \n",
    "    pt1, pt2 = (right, bottom), (left, top)\n",
    "    pt3, pt4 = (right, top), (left, bottom)\n",
    "    \n",
    "    corner = [left, right, top, bottom]\n",
    "    im_out = np.copy(im)\n",
    "    im_out = cv2.rectangle(im_out, pt1, pt2, 255, 2)\n",
    "    \n",
    "    return im_out, corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def symbol_detect(im) :\n",
    "    '''\n",
    "    Function that takes input image and processes it to obtain large binary \"blobs\"\n",
    "    around each symbol that needs to be evaluated\n",
    "    \n",
    "    Input : First Frame of video\n",
    "    Output : Mask of all symbols of first frame, minus the arrow\n",
    "    '''\n",
    "    im_arrow = detect_arrow(im)\n",
    "    im_r_a, value = initial_rectangle(im_arrow,20)       \n",
    "    im_bin = binaryImage(cv2.cvtColor(im,cv2.COLOR_BGR2GRAY))\n",
    "    \n",
    "    for i in range (value[2],value[3]):\n",
    "        for j in range (value[0], value[1]):\n",
    "            im_bin[i,j] = 255\n",
    "    im_close = binary_closing(im_bin)\n",
    "    im_dilate = binary_dilation(np.logical_not(im_close))\n",
    "    im_filt = low_pass_filter(np.logical_not(im_dilate),9)\n",
    "    return np.logical_not(im_filt).astype(int)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unvisited_neighbors(img,xy,img_label, threshold):\n",
    "    # Return unvisited neighbors\n",
    "    (x,y) = xy\n",
    "    (w,h) = img.shape\n",
    "    neighbors = []\n",
    "    \n",
    "    for i in range(x-1,x+2):\n",
    "        for j in range(y-1,y+2):\n",
    "            if i>=0 and i<w and j>=0 and j<h:\n",
    "                \n",
    "                # if the neighbor pixel satisfies the threshold and hasn't been visited yet\n",
    "                if img_label[i,j]==0 and img[i,j]>threshold:\n",
    "                    neighbors.append((i,j))\n",
    "                    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_growing(img, seed, threshold):\n",
    "    #Â Return a region starting from a pixel for a given threshold\n",
    "    \n",
    "    pixel_labels = np.zeros(img.shape)\n",
    "    stack = []\n",
    "    stack.append(seed)\n",
    "    \n",
    "    while len(stack)>0:\n",
    "        pixel_to_label = stack.pop()\n",
    "        pixel_labels[pixel_to_label] = 1\n",
    "        neighbors = get_unvisited_neighbors(img,pixel_to_label,pixel_labels, threshold)\n",
    "        \n",
    "        for i in range(len(neighbors)):\n",
    "            stack.append(neighbors[i])\n",
    "            \n",
    "            # pixel is labelled\n",
    "            pixel_labels[neighbors[i]]=1\n",
    "            \n",
    "    return pixel_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_extraction(im,threshold=0.5):\n",
    "    mask = np.copy(im)\n",
    "    (w,h) = mask.shape\n",
    "    regions = []\n",
    "    for i in range(w):\n",
    "        for j in range(h):\n",
    "            if mask[i,j] > threshold :\n",
    "                shape = region_growing(mask,(i,j),threshold)\n",
    "                mask[shape > threshold] = 0\n",
    "                nb_w_pxl = cv2.countNonZero(shape)\n",
    "                if  nb_w_pxl < 1000 and nb_w_pxl > 200 : # threshold to get rid of the larger and smaller blobs\n",
    "                    regions.append(shape)\n",
    "                    \n",
    "    return regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_object_image(mask_array, im, param):\n",
    "    '''\n",
    "        mask_array is an array of all masks\n",
    "        im is original first frame\n",
    "        param is parameter for extra width around numbers\n",
    "        \n",
    "        output is an array of all the cropped symbols    \n",
    "    '''\n",
    "    cropped_im = []\n",
    "    full_im = []\n",
    "    cropped_cm = []\n",
    "    for k in range (0,len(mask_array)) :\n",
    "        mask = mask_array[k]    \n",
    "        [h,w] = mask.shape\n",
    "        region = []\n",
    "        corner = [] \n",
    "\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                if mask[i,j] != 0:\n",
    "                    region.append([i,j])\n",
    "        region = np.array(region)\n",
    "\n",
    "        cy, cx = ndimage.measurements.center_of_mass(mask)\n",
    "        cm = (int(cx), int(cy))        \n",
    "\n",
    "        max_x = np.max(region[:,1])\n",
    "        min_x = np.min(region[:,1])\n",
    "        max_y = np.max(region[:,0])\n",
    "        min_y = np.min(region[:,0]) \n",
    "\n",
    "        left = min_x-param\n",
    "        top = min_y-param\n",
    "        right = max_x+param\n",
    "        bottom = max_y+param\n",
    "        width, hight = right-left, bottom-top\n",
    "        if width > hight : # needed to make images square\n",
    "            diff = width - hight\n",
    "            left,right = left + diff/2, right - diff/2\n",
    "        else : \n",
    "            diff = hight - width\n",
    "            top, bottom = top + diff/2, bottom - diff/2\n",
    "        \n",
    "        crop = im[int(top):int(bottom), int(left):int(right)]\n",
    "        full_im.append(crop)\n",
    "        cropped_im.append(cv2.resize(crop,dsize=(28,28),interpolation = cv2.INTER_NEAREST))\n",
    "        cropped_cm.append(cm)\n",
    "    \n",
    "    return cropped_im, full_im ,cropped_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(symb_array):\n",
    "    bin_arr = []\n",
    "    for i in range (0,len(symb_array)):\n",
    "        im_gray = cv2.cvtColor(np.max(symb_array[i])-symb_array[i],cv2.COLOR_BGR2GRAY)\n",
    "        im_gray = im_gray-np.min(im_gray)\n",
    "        im_gray = cv2.GaussianBlur(im_gray,(3,3),cv2.BORDER_CONSTANT)\n",
    "        bin_arr.append(im_gray)\n",
    "    return bin_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close(cm1,cm2):\n",
    "    threshold = 20\n",
    "    x = np.abs(cm1[0]-cm2[0])\n",
    "    y = np.abs(cm1[1]-cm2[1])\n",
    "    return x < threshold and y < threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_path(image,path,w,h,nframe):\n",
    "    a = path[:nframe]\n",
    "    for point1, point2 in zip(a, a[1:]): \n",
    "        cv2.line(image, point1, point2, [50, 50, 180], 4) \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initiate_symbol_detection():\n",
    "    image_operators = cv2.imread(\"original_operators.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    op_h, op_w = image_operators.shape\n",
    "    step = int(op_w/5)\n",
    "    im_operator = []\n",
    "    for i in range(0, op_w-step, step):\n",
    "        im_sub = image_operators[:,i+15:i+op_h+15]\n",
    "        im_sub_28 = cv2.resize(im_sub,dsize=(28,28),interpolation = cv2.INTER_LINEAR)\n",
    "        im_operator.append(im_sub_28)\n",
    "    return im_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_contour(im):\n",
    "    '''\n",
    "    Contour detection function based on the simple images we have.\n",
    "    \n",
    "    Input: grayscale image\n",
    "    Output: contour of the main feature ( In our application, handwritten digits )\n",
    "    \n",
    "    '''\n",
    "    #im = low_pass_filter(im,3)\n",
    "    contours = measure.find_contours(im, 50)\n",
    "    contours_array = []\n",
    "    for n, contour in enumerate(contours):\n",
    "        for x,y in contour:\n",
    "            contours_array.append((x,y))\n",
    "    contours_array = np.array(contours_array).astype(int)\n",
    "        \n",
    "    return contours_array\n",
    "\n",
    "def get_pixel(im):\n",
    "    #im_filtered = low_pass_filter(im,3)\n",
    "    coordinate = []\n",
    "    \n",
    "    row,col = im.shape\n",
    "    for r in range(row):\n",
    "        for c in range(col):\n",
    "            coordinate.append((r,c))\n",
    "    return coordinate\n",
    "\n",
    "def is_inside_contour(contour, non_zero_pixels):\n",
    "    counter = 0\n",
    "    for coord in non_zero_pixels:\n",
    "        dist = cv2.pointPolygonTest(contour,coord,True)\n",
    "        if dist > 0:\n",
    "            counter += 1\n",
    "    return counter\n",
    "\n",
    "def compute_perimeter(contour_list):\n",
    "    coord_tmp = []\n",
    "    counter = 0\n",
    "    nearby_point = 0\n",
    "    for coord in contour_list:\n",
    "        coord_tmp.append(coord)\n",
    "        if counter != 0:\n",
    "            if (coord_tmp[0][0] == coord_tmp[1][0]) or (coord_tmp[0][1] == coord_tmp[1][1]):\n",
    "                nearby_point += 1\n",
    "            coord_tmp.pop(0)\n",
    "        counter += 1\n",
    "    p_2 = (len(contour_list) - nearby_point)*math.sqrt(2) + nearby_point - 1\n",
    "    return p_2\n",
    "\n",
    "def compacity(im_inv) :\n",
    "    im = (np.max(im_inv)-im_inv)\n",
    "    contour = get_ordered_contour(im) \n",
    "    region_coord = get_pixel(im)\n",
    "    contour_list = contour.tolist()\n",
    "    \n",
    "    # Computing Area A_2\n",
    "    i = is_inside_contour(contour, region_coord)\n",
    "    b = len(contour)\n",
    "    area = (b/2 + i-1)\n",
    "    \n",
    "    # Computing perimeter P_2\n",
    "    perimeter = compute_perimeter(contour_list)\n",
    "    \n",
    "    # Computing compacity\n",
    "    compacity = perimeter**2/area\n",
    "    return compacity\n",
    "\n",
    "def init_operator_id() : \n",
    "    operator_typical = []\n",
    "    op_symbol = ['+', '=', '-', '/', '*']\n",
    "    for i in range(len(im_operator)):\n",
    "        operator_typical.append(compacity(im_operator[i]))\n",
    "    return operator_typical, op_symbol\n",
    "\n",
    "def init_operator_id() : \n",
    "    operator_typical = []\n",
    "    op_symbol = ['+', '=', '-', '/', '*']\n",
    "    im_operator = initiate_symbol_detection()\n",
    "    for i in range(len(im_operator)):\n",
    "        operator_typical.append(compacity(im_operator[i]))\n",
    "    return operator_typical, op_symbol  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_frames = read_video('robot_parcours_1.avi')\n",
    "path = compute_path(video_frames)\n",
    "first_frame = symbol_detect(video_frames[0])\n",
    "symbols_masks = shape_extraction(first_frame)\n",
    "symbols_images,symbol_full, symbol_cm = create_object_image(symbols_masks,video_frames[0],5)\n",
    "symbols_bin_im = features_extraction(symbols_images)\n",
    "model = keras.models.load_model('LeNet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator_typical,op_symbol = init_operator_id()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_operator_id(im_input):\n",
    "    im_filt= cv2.cvtColor(im_input,cv2.COLOR_BGR2GRAY)\n",
    "    contours = measure.find_contours(im_filt, 90)\n",
    "    if len(contours) == 2:\n",
    "        return '='\n",
    "    elif len(contours) == 3:\n",
    "        return '/'\n",
    "    else:\n",
    "        im_comp = binaryImage(im_filt)\n",
    "        comp_test = compacity(im_filt)\n",
    "        dist_ref = 1000\n",
    "        for i in range(len(operator_typical)):\n",
    "            dist = abs(comp_test-operator_typical[i])\n",
    "            if dist < dist_ref:\n",
    "                dist_ref = dist\n",
    "                id_op = i\n",
    "    return op_symbol[id_op]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit: 3\n",
      "symbol: /\n",
      "digit: 2\n",
      "symbol: +\n",
      "digit: 7\n",
      "symbol: *\n",
      "digit: 2\n",
      "symbol: =\n",
      "3 / 2 + 7 * 2 = 15.5\n"
     ]
    }
   ],
   "source": [
    "symbols_images, symbols_full, symbol_cm = create_object_image(symbols_masks,video_frames[0],10)\n",
    "w,h,c = video_frames[0].shape\n",
    "dist_between_symbols = []\n",
    "\n",
    "output = video_frames.copy()\n",
    "currently_detecting = False\n",
    "intersection = False\n",
    "counter = 0\n",
    "\n",
    "font                   = cv2.FONT_HERSHEY_SIMPLEX\n",
    "bottomLeftCornerOfText = (40,400)\n",
    "fontScale              = 1\n",
    "fontColor              = (0,150,0)\n",
    "lineType               = 2\n",
    "\n",
    "text = ''\n",
    "for n,arrow_coords in enumerate(path):\n",
    "    dist = []\n",
    "    for coord in symbol_cm:\n",
    "        norm2_dist = cv2.norm(np.array(coord),np.array(arrow_coords),cv2.NORM_L2)\n",
    "        dist.append(norm2_dist)\n",
    "    k = np.argmin(np.array(dist))\n",
    "    \n",
    "    if close(arrow_coords,symbol_cm[k]):\n",
    "        intersection = True\n",
    "    else:\n",
    "        currently_detecting = False\n",
    "        intersection = False\n",
    "        \n",
    "    if intersection and not currently_detecting:\n",
    "        currently_detecting = True \n",
    "        if not counter%2:\n",
    "            digit = symbols_bin_im[k].astype(float)\n",
    "            label = int(model.predict_classes(digit.reshape(1,28,28,1)))\n",
    "            print('digit:', label)\n",
    "            text= text + str(label) + ' '\n",
    "        else:\n",
    "            symbol = find_operator_id(symbols_full[k])\n",
    "            print('symbol:',symbol)\n",
    "            text= text + symbol + ' '\n",
    "            if symbol == '=':\n",
    "                text = text + str(eval(text[:-2]))\n",
    "                print(text)\n",
    "        counter += 1\n",
    "    output[n] = cv2.putText(output[n],text, bottomLeftCornerOfText, font, fontScale,fontColor,lineType)\n",
    "    output[n] = draw_path(output[n],path,w,h,n)\n",
    "\n",
    "writer = imageio.get_writer('test.mp4', fps=2)\n",
    "for im in output:\n",
    "    writer.append_data(cv2.cvtColor(im, cv2.COLOR_BGR2RGB))\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
