{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [IAPR 2020:][iapr2020] Lab 3 â€’  Classification\n",
    "\n",
    "**Author:** first_name_1 last_name_1, first_name_2 last_name_2, first_name_3 last_name_3  \n",
    "**Due date:** 08.05.2020\n",
    "\n",
    "[iapr2018]: https://github.com/LTS5/iapr-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract relevant data\n",
    "We first need to extract the `lab-03-data.tar.gz` archive.\n",
    "To this end, we use the [tarfile] module from the Python standard library.\n",
    "\n",
    "[tarfile]: https://docs.python.org/3.6/library/tarfile.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import os\n",
    "\n",
    "data_base_path = os.path.join(os.pardir, 'data')\n",
    "data_folder = 'lab-03-data'\n",
    "tar_path = os.path.join(data_base_path, data_folder + '.tar.gz')\n",
    "with tarfile.open(tar_path, mode='r:gz') as tar:\n",
    "    tar.extractall(path=data_base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "In this part, we will study classification based on the data available in the Matlab file `classification.mat` that you will under `lab-03-data/part1`.\n",
    "There are 3 data sets in this file, each one being a training set for a given class.\n",
    "They are contained in variables `a`, `b` and `c`.\n",
    "\n",
    "**Note**: we can load Matlab files using the [scipy.io] module.\n",
    "\n",
    "[scipy.io]: https://docs.scipy.org/doc/scipy/reference/io.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 2) (200, 2) (200, 2)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "\n",
    "data_part1_path = os.path.join(data_base_path, data_folder, 'part1', 'classification.mat')\n",
    "matfile = scipy.io.loadmat(data_part1_path)\n",
    "a = matfile['a']\n",
    "b = matfile['b']\n",
    "c = matfile['c']\n",
    "\n",
    "print(a.shape, b.shape, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Bayes method\n",
    "Using the Bayes method, give the analytical expression of the separation curves between those three classes.\n",
    "Do reasonable hypotheses about the distributions of those classes and estimate the corresponding parameters based on the given training sets.\n",
    "Draw those curves on a plot, together with the training data.\n",
    "For simplicity reasons, round the estimated parameters to the closest integer value.\n",
    "\n",
    "*Add your implementation and discussion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Mahalanobis distance\n",
    "For classes `a` and `b`, give the expression of the Mahalanobis distance used to classify a point in class `a` or `b`, and verify the obtained classification, in comparison with the \"complete\" Bayes classification, for a few points of the plane.\n",
    "\n",
    "*Add your implementation and discussion*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "In this part, we aim to classify digits using the complete version of MNIST digits dataset.\n",
    "The dataset consists of 60'000 training images and 10'000 test images of handwritten digits.\n",
    "Each image has size 28x28, and has assigned a label from zero to nine, denoting the digits value.\n",
    "Given this data, your task is to construct a Multilayer Perceptron (MLP) for supervised training and classification and evaluate it on the test images.\n",
    "\n",
    "Download the MNIST dataset (all 4 files) from http://yann.lecun.com/exdb/mnist/ under `lab-03-data/part2`.\n",
    "You can then use the script provided below to extract and load training and testing images in Python.\n",
    "\n",
    "To create an MLP you are free to choose any library.\n",
    "In case you don't have any preferences, we encourage you to use the [scikit-learn] package; it is a simple, efficient and free tool for data analysis and machine learning.\n",
    "In this [link][sklearn-example], you can find a basic example to see how to create and train an MLP using [scikit-learn].\n",
    "Your network should have the following properties:\n",
    "* Input `x`: 784-dimensional (i.e. 784 visible units representing the flattened 28x28 pixel images).\n",
    "* 100 hidden units `h`.\n",
    "* 10 output units `y`, i.e. the labels, with a value close to one in the i-th class representing a high probability of the input representing the digit `i`.\n",
    "\n",
    "If you need additional examples you can borrow some code from image classification tutorials.\n",
    "However, we recommend that you construct a minimal version of the network on your own to gain better insights.\n",
    "\n",
    "[scikit-learn]: http://scikit-learn.org/stable/index.html\n",
    "[sklearn-example]: http://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Dataset loading\n",
    "Here we first declare the methods `extract_data` and `extract_labels` so that we can reuse them later in the code.\n",
    "Then we extract both the data and corresponding labels, and plot randomly some images and corresponding labels of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_data(filename, image_shape, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(np.prod(image_shape) * image_number)\n",
    "        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "        data = data.reshape(image_number, image_shape[0], image_shape[1])\n",
    "    return data\n",
    "\n",
    "\n",
    "def extract_labels(filename, image_number):\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * image_number)\n",
    "        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = (28, 28)\n",
    "train_set_size = 60000\n",
    "test_set_size = 10000\n",
    "\n",
    "data_part2_folder = os.path.join(data_base_path, data_folder, 'part2')\n",
    "\n",
    "train_images_path = os.path.join(data_part2_folder, 'train-images-idx3-ubyte.gz')\n",
    "train_labels_path = os.path.join(data_part2_folder, 'train-labels-idx1-ubyte.gz')\n",
    "test_images_path = os.path.join(data_part2_folder, 't10k-images-idx3-ubyte.gz')\n",
    "test_labels_path = os.path.join(data_part2_folder, 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "train_images = extract_data(train_images_path, image_shape, train_set_size)\n",
    "test_images = extract_data(test_images_path, image_shape, test_set_size)\n",
    "train_labels = extract_labels(train_labels_path, train_set_size)\n",
    "test_labels = extract_labels(test_labels_path, test_set_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prng = np.random.RandomState(seed=123456789)  # seed to always re-draw the same distribution\n",
    "plt_ind = prng.randint(low=0, high=train_set_size, size=10)\n",
    "\n",
    "fig, axes = plt.subplots(1, 10, figsize=(12, 3))\n",
    "for ax, im, lb in zip(axes, train_images[plt_ind], train_labels[plt_ind]):\n",
    "    ax.imshow(im, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(lb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 MLP\n",
    "*Add your implementation and discussion*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from time import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we transform our images to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_images)\n",
    "X_test = np.array(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reshape the images into vectors we need the number of samples of the training set and the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train, w, h = X_train.shape\n",
    "N_test,_,_ = X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(N_train,-1)\n",
    "X_test = X_test.reshape(N_test,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We standerdize the data to avoid overflows and its always a good thing. Moreover, we will be using PCA in order to improve the classification. For that, data need to be standerdized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set\n",
    "X_train_pca = scaler.transform(X_train, copy= False)\n",
    "X_test_pca = scaler.transform(X_test, copy= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we use logistic regression in order to classify our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   21.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total time is 257.4637289047241 seconds \n",
      "0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
     ]
    }
   ],
   "source": [
    "tic = time()\n",
    "\n",
    "# Fit a linear regression model\n",
    "clf = LogisticRegression(solver ='lbfgs', tol = 1e-2, max_iter = 1000, random_state=0,verbose=2).fit(X_train, train_labels)\n",
    "# Compute the classification score\n",
    "score = clf.score(X_test,test_labels)\n",
    "\n",
    "toc = time()\n",
    "print('The total time is %s seconds ' % (toc-tic))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we try to improve our accuracy with PCA. We take 95% of the energy of the data. lower than that, the accuracy decreases. This is quite expected as the PCA decreases information held by the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.95)\n",
    "pca.fit(X_train)\n",
    "origi_img = X_train\n",
    "trans_img = pca.fit_transform(origi_img)\n",
    "trans_img = pca.inverse_transform(trans_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e57c7ecb4c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Fit a logistic regression model on the PCA coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                         \u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1604\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1606\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1608\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfprime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m                 iprint=iprint, pgtol=tol, maxiter=max_iter)\n\u001b[0m\u001b[1;32m    945\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"warnflag\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m                 warnings.warn(\"lbfgs failed to converge. Increase the number \"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfmin_l_bfgs_b\u001b[0;34m(func, x0, fprime, args, approx_grad, bounds, m, factr, pgtol, epsilon, iprint, maxfun, maxiter, disp, callback, maxls)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     res = _minimize_lbfgsb(fun, x0, args=args, jac=jac, bounds=bounds,\n\u001b[0;32m--> 199\u001b[0;31m                            **opts)\n\u001b[0m\u001b[1;32m    200\u001b[0m     d = {'grad': res['jac'],\n\u001b[1;32m    201\u001b[0m          \u001b[0;34m'task'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'message'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, **unknown_options)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36mfunc_and_grad\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(*wrapper_args)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mwrapper_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mncalls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36m_logistic_loss_and_grad\u001b[0;34m(w, X, y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mz0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;31m# Case where we fit the intercept.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trans_test = pca.fit_transform(X_test)\n",
    "trans_test = pca.inverse_transform(trans_test)\n",
    "tic = time()\n",
    "\n",
    "# Fit a logistic regression model on the PCA coefficients\n",
    "clf = LogisticRegression(solver ='lbfgs', tol = 1e-2, max_iter = 1000, random_state=0,verbose=2)\\\n",
    "                        .fit(trans_img, train_labels)\n",
    "\n",
    "score = clf.score(trans_test,test_labels)\n",
    "\n",
    "toc = time()\n",
    "\n",
    "print('The total time is %s seconds' % (toc-tic))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement of the accuracy by 1.6%.\n",
    "In the next step, we will use CNN which is a promising machine learning technique. CNN mimic human way to recognize images which explains its very good results and diffrent image classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to reshape the images in order to feed it to the network. Conv2D need a 4 dimension input (N_samples, im_width, im_height, n_color_space). n_color_space is 1 in this case since we have grayscale images.\n",
    "Moreover, this is a multiclassification problem, so we need to transform the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_images).reshape(N_train,w,h,1)\n",
    "x_test = np.array(test_images).reshape(N_test,w,h,1)\n",
    "\n",
    "y_train = np.zeros((N_train,10))\n",
    "for n, i in enumerate(train_labels):\n",
    "    y_train[n][i] = 1\n",
    "    \n",
    "y_test = np.zeros((N_test,10))\n",
    "for n, i in enumerate(test_labels):\n",
    "    y_test[n][i] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose the following architecture. 3 convolution layers, and 3 hidden layers and one output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_18 (Averag (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 11, 11, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_19 (Averag (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "IMG_HEIGHT = 28\n",
    "IMG_WIDTH = 28\n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.AveragePooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=45, horizontal_flip=True, vertical_flip=True)\n",
    "training_data = datagen.flow(x_train,y_train,batch_size = 100)\n",
    "testing_data = datagen.flow(x_test,y_test,batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 600 steps, validate for 100 steps\n",
      "Epoch 1/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.2813 - accuracy: 0.9077 - val_loss: 0.1995 - val_accuracy: 0.9247\n",
      "Epoch 2/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.1829 - accuracy: 0.9308 - val_loss: 0.1618 - val_accuracy: 0.9390\n",
      "Epoch 3/10\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.1529 - accuracy: 0.9430 - val_loss: 0.1392 - val_accuracy: 0.9481\n",
      "Epoch 4/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.1353 - accuracy: 0.9505 - val_loss: 0.1255 - val_accuracy: 0.9542\n",
      "Epoch 5/10\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.1229 - accuracy: 0.9556 - val_loss: 0.1170 - val_accuracy: 0.9571\n",
      "Epoch 6/10\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.1137 - accuracy: 0.9592 - val_loss: 0.1054 - val_accuracy: 0.9614\n",
      "Epoch 7/10\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.1066 - accuracy: 0.9617 - val_loss: 0.0982 - val_accuracy: 0.9648\n",
      "Epoch 8/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.1003 - accuracy: 0.9642 - val_loss: 0.0924 - val_accuracy: 0.9671\n",
      "Epoch 9/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0952 - accuracy: 0.9662 - val_loss: 0.0883 - val_accuracy: 0.9683\n",
      "Epoch 10/10\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0911 - accuracy: 0.9676 - val_loss: 0.0834 - val_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "history = model.fit(training_data, epochs=epochs, validation_data = testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, CNN offers an almost perfect classification. We get up to 99.31% of accuracy in our validation set. We will definately use this model in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsh1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
